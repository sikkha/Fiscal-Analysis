library(tidyquant)
library(tidyverse)
# Get data
symbols <- c("SPY", "EEM", "SHY", "IYR", "GLD")
symbols_low <- tolower(symbols)
prices <- getSymbols(symbols, src = "yahoo",
from = "1990-01-01",
auto.assign = TRUE) %>%
map(~Ad(get(.))) %>%
reduce(merge) %>%
`colnames<-`(symbols_low)
prices_monthly <- to.monthly(prices, indexAt = "last", OHLC = FALSE)
ret <- ROC(prices_monthly)["2005/2019"]
naive <- ret[,c("spy", "shy")]
basic <- ret[,c("spy", "shy", "gld")]
# Create different weights and portflios
wt1 <- rep(1/(ncol(basic)), ncol(basic))
port1 <- Return.portfolio(basic, wt1) %>%
`colnames<-`("ret")
wt2 <- c(0.9, 0.10, 0)
port2 <- Return.portfolio(basic, weights = wt2) %>%
`colnames<-`("ret")
wtn <- c(0.5, 0.5)
portn <- Return.portfolio(naive, wtn)
port_comp <- data.frame(date = index(port1), equal = as.numeric(port1),
wtd = as.numeric(port2),
naive = as.numeric(portn))
port_comp %>%
gather(key,value, -date) %>%
group_by(key) %>%
mutate(value = cumprod(value+1)) %>%
ggplot(aes(date, value*100, color = key)) +
geom_line() +
scale_color_manual("", labels = c("Equal", "Naive", "Risky"),
values = c("blue", "black", "red")) +
labs(x = "",
y = "Index",
title = "Three portfolios, which is best?",
caption = "Source: Yahoo, OSM estimates") +
theme(legend.position = "top",
plot.caption = element_text(hjust = 0))
# Portfolio summary table
port_comp %>%
rename("Equal" = equal,
"Naive" = naive,
"Risky" = wtd) %>%
gather(Asset, value, -date) %>%
group_by(Asset) %>%
summarise(`Mean (%)` = round(mean(value, na.rm = TRUE),3)*1200,
`Volatility (%)` = round(sd(value, na.rm = TRUE)*sqrt(12),3)*100,
`Risk-adjusted (%)` = round(mean(value, na.rm = TRUE)/sd(value, na.rm=TRUE)*sqrt(12),3)*100,
`Cumulative (%)` = round(prod(1+value, na.rm = TRUE),3)*100) %>%
knitr::kable(caption = "Annualized performance metrics")
# Semi-deviation functions
down_dev <- function(vec){
mean_vec <- mean(vec, na.rm = TRUE)
down_vec <- vec[vec < mean_vec]
dev <- sqrt(mean((down_vec - mean_vec)^2))
dev
}
up_dev <- function(vec){
mean_vec <- mean(vec, na.rm = TRUE)
up_vec <- vec[vec > mean_vec]
dev <- sqrt(mean((up_vec - mean_vec)^2))
dev
}
# Semi-deviation table
port_comp %>%
rename("Equal" = equal,
"Naive" = naive,
"Risky" = wtd) %>%
gather(Asset, value, -date) %>%
group_by(Asset) %>%
summarise(`Down volatility (%)` = round(down_dev(value)*sqrt(12),3)*100,
`Up volatility(%)` = round(up_dev(value)*sqrt(12),3)*100) %>%
knitr::kable(caption = "Annualized performance metrics")
## Portfolio simulations
# Portfolio
mean_ret <- apply(ret[,c("spy", "shy", "gld")],2,mean)
cov_port <- cov(ret[,c("spy", "shy", "gld")])
port_exam <- data.frame(ports = colnames(port_comp)[-1],
ret = as.numeric(apply(port_comp[,-1],2, mean)),
vol = as.numeric(apply(port_comp[,-1], 2, sd)))
# Weighting that ensures more variation and random weighthing to stocks
set.seed(123)
wts <- matrix(nrow = 1000, ncol = 3)
for(i in 1:1000){
a <- runif(1,0,1)
b <- c()
for(j in 1:2){
b[j] <- runif(1,0,1-sum(a,b))
}
if(sum(a,b) < 1){
inc <- (1-sum(a,b))/3
vec <- c(a+inc, b+inc)
}else{
vec <- c(a,b)
}
wts[i,] <- sample(vec,replace = FALSE)
}
# Calculate random portfolios
port <- matrix(nrow = 1000, ncol = 2)
for(i in 1:1000){
port[i,1] <- as.numeric(sum(wts[i,] * mean_ret))
port[i,2] <- as.numeric(sqrt(t(wts[i,] %*% cov_port %*% wts[i,])))
}
colnames(port) <- c("returns", "risk")
port <- as.data.frame(port)
# Graph with points
port %>%
ggplot(aes(risk*sqrt(12)*100, returns*1200)) +
geom_point(color = "blue", size = 1.2, alpha = 0.4) +
geom_smooth(method = "loess", formula = y ~ log(x), se = FALSE, color = "slategrey") +
geom_point(data = port_exam, aes(port_exam[1,3]*sqrt(12)*100,
port_exam[1,2]*1200),
color = "red", size = 6) +
geom_point(data = port_exam, aes(port_exam[2,3]*sqrt(12)*100,
port_exam[2,2]*1200),
color = "purple", size = 7) +
geom_point(data = port_exam, aes(port_exam[3,3]*sqrt(12)*100,
port_exam[3,2]*1200),
color = "black", size = 5) +
scale_x_continuous(limits = c(0,14)) +
labs(x = "Risk (%)",
y = "Return (%)",
title = "Simulated portfolios")
# Dominated portfolios
naive_dom <- port %>%
filter(risk < port_exam[3,3]+0.0005,
risk > port_exam[3,3]-0.0005) %>%
summarise(round(max(returns) - port_exam[3,2],4)*1200+.02) %>%
as.numeric()
equal_dom <- port %>%
filter(risk < port_exam[1,3]+0.0005,
risk > port_exam[1,3]-0.0005) %>%
summarise(round(max(returns) - port_exam[1,2],3)*1200) %>%
as.numeric()
risky_dom <- port %>%
filter(risk < port_exam[2,3]+0.0005,
risk > port_exam[2,3]-0.0005) %>%
summarise(round(max(returns) - port_exam[2,2],4)*1200+.02) %>%
as.numeric()
# Finad max and equivalent risk for Equal risk slice
equal_max <- port %>%
filter(risk < port_exam[1,3]+0.0005,
risk > port_exam[1,3]-0.0005) %>%
mutate(returns = returns*1200,
risk = risk * sqrt(12)*100) %>%
arrange(desc(returns)) %>%
slice(1)
# Find wieghts for dominant portfolio
eq_wt <- port %>%
mutate(spy_wt = wts[,1],
shy_wt = wts[,2],
gld_wt = wts[,3],
returns = returns * 1200,
risk = risk * sqrt(12) *100) %>%
filter(returns == equal_max$returns,
risk == equal_max$risk) %>%
select(spy_wt, shy_wt, gld_wt)
# Graph weights
eq_wt %>%
rename("SPY" = spy_wt,
"SHY" = shy_wt,
"GLD" = gld_wt) %>%
gather(key,value) %>%
ggplot(aes(factor(key, level = c("SPY", "SHY", "GLD")), value*100)) +
geom_bar(stat = 'identity', fill = "blue") +
geom_text(aes(label = round(value,2)*100), nudge_y = 5) +
labs(x = "Assets",
y = "Weights (%)",
title = "Derived weighting to improve returns")
# Assignment1
# Loading
library("tidyverse")
library("readxl")
#setwd("~/Desktop/workspace/DA8410 Fiscal and Monetary Policy Analysis/DA8410 Part 2")
setwd("~/Documents/GitHub/Public-Education-Policy-and-Spending/data")
# xls files
#my_data <- read_excel("DA.841,PA8603-DATA.xls")
my_data <- read.csv("DA.841,PA8603-DATA_CSV.csv")
#data check (for debug purpose)
#head("my_data", 4)
#print(my_data)
#demand-side explanation
#Model1: examining all independent variables
## old version
model1 <- lm(GEDU ~ GDP + POP + URB + GLOBAL + INEQTY + REV + TRADE + LABOR + DGOV + GEDUtm1, data = my_data)
#summary(model1) $coefficient
summary(model1)
confint (model1)
## new version
#fitted.model1 <- lm(GEDU ~ GDP + POP + URB + GLOBAL + INEQTY + REV + TRADE + LABOR + DGOV + GEDUtm1, data = my_data)
#summary(model1) $coefficient
#confint (model1)
#Model2: Wagner's law
model2 <- lm(GEDU ~ GDP + POP + URB + REV, data = my_data)
model2_1 <- lm(GEDU ~ POP + URB + REV, data = my_data)
model2_2 <- lm(GEDU ~ GDP + POP + URB, data = my_data)
summary(model2)
confint(model2)
summary(model2_1)
confint(model2_1)
summary(model2_2)
confint(model2_2)
#Model3: Compensation Theory
model3 <- lm(GEDU ~ GLOBAL + DGOV, data = my_data)
summary(model3)
confint(model3)
#Model4: Median Voter
model4 <- lm(GEDU ~ INEQTY + DGOV, data = my_data)
summary(model4)
confint(model4)
#Model5: Interest Group Theory
model5 <- lm(GEDU ~ TRADE + LABOR, data = my_data)
summary(model5)
confint(model5)
#Supply-Side Explanation
#Model 6: Incrementalism Theory
model6 <- lm(GEDU ~ GEDUtm1, data = my_data)
summary(model6)
confint(model6)
#library(car)
#vif(model1)
#check for multicollinearity problem
library(corpcor)
cor2pcor(cov(model1))
library(mctest)
imcdiag(mod = model1, method = "VIF", vif = 5)
imcdiag(mod = model2, method = "VIF", vif = 5)
imcdiag(mod = model2_1, method = "VIF", vif = 5)
imcdiag(mod = model2_2, method = "VIF", vif = 5)
imcdiag(mod = model3, method = "VIF", vif = 5)
imcdiag(mod = model4, method = "VIF", vif = 5)
imcdiag(mod = model5, method = "VIF", vif = 5)
imcdiag(mod = model6, method = "VIF", vif = 5)
#library(GGally)
#ggpairs(mydata)
#ggpairs(my_data, c('GEDU', 'GDP', 'POP', 'URB', 'GLOBAL', 'INEQTY', 'REV', 'TRADE', 'LABOR', 'DGOV', 'GEDUtm1'))
#library(car)
#crPlots(model1)
#crPlots(model2_1)
#crPlots(model3)
#crPlots(model4)
#crPlots(model5)
#crPlots(model6)
library(apaTables)
apa.reg.table(model1)
library(stargazer)
stargazer(model1, model2_1, model3, model4, model5, model6, type="text")
library(broom)
tidy(model1)
# Assignment1
# Loading
library("tidyverse")
library("readxl")
#setwd("~/Desktop/workspace/DA8410 Fiscal and Monetary Policy Analysis/DA8410 Part 2")
setwd("~/Documents/GitHub/Fiscal-Analysis/Public-Education-Policy-and-Spending/data")
# xls files
#my_data <- read_excel("DA.841,PA8603-DATA.xls")
my_data <- read.csv("DA.841,PA8603-DATA_CSV.csv")
#data check (for debug purpose)
#head("my_data", 4)
#print(my_data)
#demand-side explanation
#Model1: examining all independent variables
## old version
model1 <- lm(GEDU ~ GDP + POP + URB + GLOBAL + INEQTY + REV + TRADE + LABOR + DGOV + GEDUtm1, data = my_data)
#summary(model1) $coefficient
summary(model1)
confint (model1)
## new version
#fitted.model1 <- lm(GEDU ~ GDP + POP + URB + GLOBAL + INEQTY + REV + TRADE + LABOR + DGOV + GEDUtm1, data = my_data)
#summary(model1) $coefficient
#confint (model1)
#Model2: Wagner's law
model2 <- lm(GEDU ~ GDP + POP + URB + REV, data = my_data)
model2_1 <- lm(GEDU ~ POP + URB + REV, data = my_data)
model2_2 <- lm(GEDU ~ GDP + POP + URB, data = my_data)
summary(model2)
confint(model2)
summary(model2_1)
confint(model2_1)
summary(model2_2)
confint(model2_2)
#Model3: Compensation Theory
model3 <- lm(GEDU ~ GLOBAL + DGOV, data = my_data)
summary(model3)
confint(model3)
#Model4: Median Voter
model4 <- lm(GEDU ~ INEQTY + DGOV, data = my_data)
summary(model4)
confint(model4)
#Model5: Interest Group Theory
model5 <- lm(GEDU ~ TRADE + LABOR, data = my_data)
summary(model5)
confint(model5)
#Supply-Side Explanation
#Model 6: Incrementalism Theory
model6 <- lm(GEDU ~ GEDUtm1, data = my_data)
summary(model6)
confint(model6)
#library(car)
#vif(model1)
#check for multicollinearity problem
library(corpcor)
cor2pcor(cov(model1))
library(mctest)
imcdiag(mod = model1, method = "VIF", vif = 5)
imcdiag(mod = model2, method = "VIF", vif = 5)
imcdiag(mod = model2_1, method = "VIF", vif = 5)
imcdiag(mod = model2_2, method = "VIF", vif = 5)
imcdiag(mod = model3, method = "VIF", vif = 5)
imcdiag(mod = model4, method = "VIF", vif = 5)
imcdiag(mod = model5, method = "VIF", vif = 5)
imcdiag(mod = model6, method = "VIF", vif = 5)
#library(GGally)
#ggpairs(mydata)
#ggpairs(my_data, c('GEDU', 'GDP', 'POP', 'URB', 'GLOBAL', 'INEQTY', 'REV', 'TRADE', 'LABOR', 'DGOV', 'GEDUtm1'))
#library(car)
#crPlots(model1)
#crPlots(model2_1)
#crPlots(model3)
#crPlots(model4)
#crPlots(model5)
#crPlots(model6)
library(apaTables)
apa.reg.table(model1)
library(stargazer)
stargazer(model1, model2_1, model3, model4, model5, model6, type="text")
library(broom)
tidy(model1)
# Assignment1
# Loading
library("tidyverse")
library("readxl")
#setwd("~/Desktop/workspace/DA8410 Fiscal and Monetary Policy Analysis/DA8410 Part 2")
setwd("~/Documents/GitHub/Fiscal-Analysis/Public-Education-Policy-and-Spending/data")
# xls files
#my_data <- read_excel("DA.841,PA8603-DATA.xls")
my_data <- read.csv("DA.841,PA8603-DATA_CSV.csv")
#data check (for debug purpose)
#head("my_data", 4)
#print(my_data)
#demand-side explanation
#Model1: examining all independent variables
## old version
model1 <- lm(GEDU ~ GDP + POP + URB + GLOBAL + INEQTY + REV + TRADE + LABOR + DGOV + GEDUtm1, data = my_data)
#summary(model1) $coefficient
summary(model1)
confint (model1)
## new version
#fitted.model1 <- lm(GEDU ~ GDP + POP + URB + GLOBAL + INEQTY + REV + TRADE + LABOR + DGOV + GEDUtm1, data = my_data)
#summary(model1) $coefficient
#confint (model1)
#Model2: Wagner's law
model2 <- lm(GEDU ~ GDP + POP + URB + REV, data = my_data)
model2_1 <- lm(GEDU ~ POP + URB + REV, data = my_data)
model2_2 <- lm(GEDU ~ GDP + POP + URB, data = my_data)
summary(model2)
confint(model2)
summary(model2_1)
confint(model2_1)
summary(model2_2)
confint(model2_2)
#Model3: Compensation Theory
model3 <- lm(GEDU ~ GLOBAL + DGOV, data = my_data)
summary(model3)
confint(model3)
#Model4: Median Voter
model4 <- lm(GEDU ~ INEQTY + DGOV, data = my_data)
summary(model4)
confint(model4)
#Model5: Interest Group Theory
model5 <- lm(GEDU ~ TRADE + LABOR, data = my_data)
summary(model5)
confint(model5)
#Supply-Side Explanation
#Model 6: Incrementalism Theory
model6 <- lm(GEDU ~ GEDUtm1, data = my_data)
summary(model6)
confint(model6)
#library(car)
#vif(model1)
#check for multicollinearity problem
library(corpcor)
cor2pcor(cov(model1))
library(mctest)
imcdiag(mod = model1, method = "VIF", vif = 5)
imcdiag(mod = model2, method = "VIF", vif = 5)
imcdiag(mod = model2_1, method = "VIF", vif = 5)
imcdiag(mod = model2_2, method = "VIF", vif = 5)
imcdiag(mod = model3, method = "VIF", vif = 5)
imcdiag(mod = model4, method = "VIF", vif = 5)
imcdiag(mod = model5, method = "VIF", vif = 5)
imcdiag(mod = model6, method = "VIF", vif = 5)
#library(GGally)
#ggpairs(mydata)
#ggpairs(my_data, c('GEDU', 'GDP', 'POP', 'URB', 'GLOBAL', 'INEQTY', 'REV', 'TRADE', 'LABOR', 'DGOV', 'GEDUtm1'))
#library(car)
#crPlots(model1)
#crPlots(model2_1)
#crPlots(model3)
#crPlots(model4)
#crPlots(model5)
#crPlots(model6)
library(apaTables)
apa.reg.table(model1)
library(stargazer)
stargazer(model1, model2_1, model3, model4, model5, model6, type="text")
library(broom)
tidy(model1)
stargazer(model1, model3)
stargazer(model1, model2_1, model3, model4, model5, model6, out="stargazer.tex")
st_entity < stargazer(model1, model2_1, model3, model4, model5, model6, type="text")
st_entity <- stargazer(model1, model2_1, model3, model4, model5, model6, type="text")
st_entity
apa.reg.table(st_entity)
apa.reg.table(model1, model2, model3)
stargazer(model1, model2_1, model3, model4, model5, model6, type="text")
tidy(model1)
tidy(my_data)
model1 <- lm(GEDU ~ GDP + POP + URB + GLOBAL + INEQTY + REV + TRADE + LABOR + DGOV + GEDUtm1, data = my_data)
tidy(my_data)
tidy(model1)
my_data
# Assignment1
# Loading
library("tidyverse")
library("readxl")
#setwd("~/Desktop/workspace/DA8410 Fiscal and Monetary Policy Analysis/DA8410 Part 2")
setwd("~/Documents/GitHub/Fiscal-Analysis/Public-Education-Policy-and-Spending/data")
# xls files
#my_data <- read_excel("DA.841,PA8603-DATA.xls")
my_data <- read.csv("DA.841,PA8603-DATA_CSV.csv")
#data check (for debug purpose)
#head("my_data", 4)
#print(my_data)
#demand-side explanation
#Model1: examining all independent variables
## old version
model1 <- lm(GEDU ~ GDP + POP + URB + GLOBAL + INEQTY + REV + TRADE + LABOR + DGOV + GEDUtm1, data = my_data)
#summary(model1) $coefficient
summary(model1)
confint (model1)
## new version
#fitted.model1 <- lm(GEDU ~ GDP + POP + URB + GLOBAL + INEQTY + REV + TRADE + LABOR + DGOV + GEDUtm1, data = my_data)
#summary(model1) $coefficient
#confint (model1)
#Model2: Wagner's law
model2 <- lm(GEDU ~ GDP + POP + URB + REV, data = my_data)
model2_1 <- lm(GEDU ~ POP + URB + REV, data = my_data)
model2_2 <- lm(GEDU ~ GDP + POP + URB, data = my_data)
summary(model2)
confint(model2)
summary(model2_1)
confint(model2_1)
summary(model2_2)
confint(model2_2)
#Model3: Compensation Theory
model3 <- lm(GEDU ~ GLOBAL + DGOV, data = my_data)
summary(model3)
confint(model3)
#Model4: Median Voter
model4 <- lm(GEDU ~ INEQTY + DGOV, data = my_data)
summary(model4)
confint(model4)
#Model5: Interest Group Theory
model5 <- lm(GEDU ~ TRADE + LABOR, data = my_data)
summary(model5)
confint(model5)
#Supply-Side Explanation
#Model 6: Incrementalism Theory
model6 <- lm(GEDU ~ GEDUtm1, data = my_data)
summary(model6)
confint(model6)
#library(car)
#vif(model1)
#check for multicollinearity problem
library(corpcor)
cor2pcor(cov(model1))
library(mctest)
imcdiag(mod = model1, method = "VIF", vif = 5)
imcdiag(mod = model2, method = "VIF", vif = 5)
imcdiag(mod = model2_1, method = "VIF", vif = 5)
imcdiag(mod = model2_2, method = "VIF", vif = 5)
imcdiag(mod = model3, method = "VIF", vif = 5)
imcdiag(mod = model4, method = "VIF", vif = 5)
imcdiag(mod = model5, method = "VIF", vif = 5)
imcdiag(mod = model6, method = "VIF", vif = 5)
#library(GGally)
#ggpairs(mydata)
#ggpairs(my_data, c('GEDU', 'GDP', 'POP', 'URB', 'GLOBAL', 'INEQTY', 'REV', 'TRADE', 'LABOR', 'DGOV', 'GEDUtm1'))
#library(car)
#crPlots(model1)
#crPlots(model2_1)
#crPlots(model3)
#crPlots(model4)
#crPlots(model5)
#crPlots(model6)
library(apaTables)
apa.reg.table(model1)
library(stargazer)
stargazer(model1, model2_1, model3, model4, model5, model6, type="text")
library(broom)
tidy(model1)
stargazer(model1, model2_1, model3, model4, model5, model6, out="stargazer2.tex")
ggpairs(my_data)
library(GGally)
ggpairs(my_data)
ggpairs(my_data, c('GEDU', 'GDP', 'POP', 'URB', 'GLOBAL', 'INEQTY', 'REV', 'TRADE', 'LABOR', 'DGOV', 'GEDUtm1'))
tidy(model1)
